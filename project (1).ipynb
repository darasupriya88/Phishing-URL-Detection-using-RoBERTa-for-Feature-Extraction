{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7066012,"sourceType":"datasetVersion","datasetId":4068621},{"sourceId":7094155,"sourceType":"datasetVersion","datasetId":4088447}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Code","metadata":{}},{"cell_type":"markdown","source":"Run the cell below to remove old save files","metadata":{}},{"cell_type":"code","source":"import os\nos.remove(\"/kaggle/working/roberta_phishing_model_metrics.pkl\")\nos.remove(\"/kaggle/working/state.db\")\nos.remove(\"/kaggle/working/roberta_phishing_model_fold_1.pkl\")\nos.remove(\"/kaggle/working/roberta_phishing_model_fold_2.pkl\")\nos.remove(\"/kaggle/working/roberta_phishing_model_fold_3.pkl\")\nos.remove(\"/kaggle/working/roberta_phishing_model_fold_4.pkl\")\nos.remove(\"/kaggle/working/roberta_phishing_model_fold_5.pkl\")","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:59:08.997187Z","iopub.execute_input":"2023-11-28T15:59:08.997597Z","iopub.status.idle":"2023-11-28T15:59:09.743409Z","shell.execute_reply.started":"2023-11-28T15:59:08.997563Z","shell.execute_reply":"2023-11-28T15:59:09.741592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 1: 5 Fold CV","metadata":{}},{"cell_type":"markdown","source":"**Dataset Loading and Preparation**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, roc_curve, auc, f1_score, confusion_matrix, precision_score, recall_score\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AdamW, get_scheduler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import RandomSampler, SequentialSampler\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn.metrics import roc_auc_score\nimport pickle\n\n\n# Load the dataset\ndataset = pd.read_csv(\"/kaggle/input/phishing-urls/phishing_site_urls.csv\").sample(n=50000, random_state=42)\n\n# Data Preprocessing and remove missing values\ndataset = dataset.dropna()\n\n# Map 'good' to 0 and 'bad' to 1\ndataset['Label'] = dataset['Label'].map({'good': 0, 'bad': 1})\n\n# Tokenizer and model initialization\nmodel_name = \"roberta-base\"\ntokenizer = RobertaTokenizer.from_pretrained(model_name,local_files_only=False)\nmodel = RobertaForSequenceClassification.from_pretrained(model_name,local_files_only=False)\n\n# Cross-validation setup\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Initialize variables for loss\nsteps = []\nlosses = []\n\n# Parallelize over available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T15:59:16.612906Z","iopub.execute_input":"2023-11-28T15:59:16.613634Z","iopub.status.idle":"2023-11-28T15:59:32.421301Z","shell.execute_reply.started":"2023-11-28T15:59:16.613588Z","shell.execute_reply":"2023-11-28T15:59:32.420341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cross Validation Loop**","metadata":{}},{"cell_type":"code","source":"all_y_true=[]\nall_y_pred=[]\nfor fold, (train_idx, val_idx) in enumerate(skf.split(dataset['URL'], dataset['Label'])):\n    print(f\"\\nFold {fold + 1}/{skf.n_splits}\")\n    model_name = \"roberta-base\"\n    tokenizer = RobertaTokenizer.from_pretrained(model_name,local_files_only=False)\n    model = RobertaForSequenceClassification.from_pretrained(model_name,local_files_only=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    if torch.cuda.device_count() > 1:\n        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n        model = torch.nn.DataParallel(model)\n\n    # Split the dataset into training and validation sets\n    train_data = dataset.iloc[train_idx]\n    val_data = dataset.iloc[val_idx]\n\n    # Tokenize and encode the input text for training and validation\n    train_encodings = tokenizer(list(train_data['URL']), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n    val_encodings = tokenizer(list(val_data['URL']), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n\n    # Create DataLoader for training and validation data\n    train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(list(train_data['Label'])))\n    val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(list(val_data['Label'])))\n\n    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)\n    val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=64)\n\n    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n\n    # Fine-tuning\n    epochs = 4\n    total_steps = len(train_dataloader) * epochs\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n    loss_fn = torch.nn.CrossEntropyLoss()\n\n    # Model training loop\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        model.train()\n        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch + 1}/{epochs}', leave=False)\n        for step, batch in progress_bar:\n            train_input_ids, train_attention_mask, labels = batch\n            train_input_ids = train_input_ids.to(device)\n            train_attention_mask = train_attention_mask.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(train_input_ids, attention_mask=train_attention_mask, labels=labels)\n            loss = outputs.loss.mean()\n            #loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            # Append loss values\n            steps.append(len(steps) + 1)\n            losses.append(loss.item())\n        \n    model.eval()\n    val_losses = []\n    val_predictions = []\n    val_true_labels = []\n    with torch.no_grad():\n        for val_batch in val_dataloader:\n            val_input_ids, val_attention_mask, val_labels = val_batch\n            val_input_ids = val_input_ids.to(device)\n            val_attention_mask = val_attention_mask.to(device)\n            val_labels = val_labels.to(device)\n\n            val_outputs = model(val_input_ids, attention_mask=val_attention_mask, labels=val_labels)\n            val_loss = val_outputs.loss.mean().item()\n            val_predictions.extend(torch.argmax(val_outputs.logits, dim=1).cpu().numpy())\n            val_true_labels.extend(val_labels.cpu().numpy())\n            val_losses.append(val_loss)\n\n    # Calculate validation metrics\n    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n    val_f1 = f1_score(val_true_labels, val_predictions, average='weighted')\n    val_roc_auc = roc_auc_score(val_true_labels, val_predictions)\n    val_precision = precision_score(val_true_labels, val_predictions, average='weighted')\n    val_recall = recall_score(val_true_labels, val_predictions, average='weighted')\n    val_classification_report = classification_report(val_true_labels, val_predictions)\n\n    print(f\"Validation Loss: {np.mean(val_losses):.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}, ROC AUC: {val_roc_auc:.4f}\")\n    print(f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n    print(\"Classification Report:\\n\", val_classification_report)\n    # Append predictions and true labels for each fold\n    all_y_true.extend(val_true_labels)\n    all_y_pred.extend(val_predictions)\n    \n\n    # Save the trained model for each fold\n    model_save_path = f\"roberta_phishing_model_fold_{fold + 1}.pkl\"\n    model_state = {\n        'model': model.state_dict(),\n        'tokenizer': tokenizer,\n        'train_dataloader': train_dataloader,\n        'val_dataloader': val_dataloader,\n        'val_true_labels': val_true_labels,\n        'val_predictions': val_predictions,\n        'val_f1': val_f1,\n        'val_roc': val_roc_auc,\n        'val_prec': val_precision,\n        'val_recall': val_recall,\n        'val_classification':val_classification_report\n    }\n    with open(model_save_path, 'wb') as model_file:\n        pickle.dump(model_state, model_file)\n        \n# Save the overall model predictions\nresult_save_path = f\"roberta_phishing_model_metrics.pkl\"\nmetrics = {\n    'y_true': all_y_true,\n    'y_pred': all_y_pred\n}\nwith open(result_save_path, 'wb') as model_file:\n    pickle.dump(metrics, model_file)\n\n# Calculate overall metrics after all folds\naccuracy = accuracy_score(all_y_true, all_y_pred)\nclassification_rep = classification_report(all_y_true, all_y_pred, target_names=['good','bad'])\nconf_matrix = confusion_matrix(all_y_true, all_y_pred)\nprecision, recall, _ = precision_recall_curve(all_y_true, all_y_pred)\nfpr, tpr, _ = roc_curve(all_y_true, all_y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Class Imbalance Visualization\nplt.figure(figsize=(8, 6))\nsns.countplot(x='Label', data=dataset)\nplt.title('Class Distribution')\nplt.show()\n\n# Precision-Recall Curve\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, marker='.')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.show()\n\n# ROC Curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:59:48.440483Z","iopub.execute_input":"2023-11-28T15:59:48.440906Z","iopub.status.idle":"2023-11-29T01:01:01.828485Z","shell.execute_reply.started":"2023-11-28T15:59:48.440874Z","shell.execute_reply":"2023-11-29T01:01:01.827637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Print the calculated metrics**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score,roc_auc_score, precision_recall_curve, roc_curve, auc, f1_score, confusion_matrix, precision_score, recall_score\nimport pickle\nwith open('/kaggle/input/metrics/roberta_phishing_model_metrics.pkl', 'rb') as model_file:\n    model_state = pickle.load(model_file)\n    \nall_y_true = model_state['y_true']\nall_y_pred = model_state['y_pred']\n\naccuracy = accuracy_score(all_y_true, all_y_pred)\nclassification_rep = classification_report(all_y_true, all_y_pred, target_names=['good','bad'])\nf1score = f1_score(all_y_true, all_y_pred, average='weighted')\nprint(\"AUROC: \",roc_auc_score(all_y_true, all_y_pred))\nprint(\"Accuracy: \",accuracy)\nprint(\"F1 score: \",f1score)\nprint(classification_rep)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T22:18:10.958503Z","iopub.execute_input":"2023-11-30T22:18:10.958874Z","iopub.status.idle":"2023-11-30T22:18:11.292032Z","shell.execute_reply.started":"2023-11-30T22:18:10.958849Z","shell.execute_reply":"2023-11-30T22:18:11.291018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 2: Train/Test Split","metadata":{}},{"cell_type":"markdown","source":"**Without Class Weights**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, roc_curve, auc, f1_score\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW, get_scheduler\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, auc\nimport seaborn as sns\n\n\n# Load the dataset\ndataset = pd.read_csv(\"/kaggle/input/phishing-site-urls/phishing_site_urls.csv\")\n\n# Data Preprocessing and remove missing values\ndataset = dataset.dropna()\n\n# Encode labels (good and bad) to numerical values\nlabel_encoder = LabelEncoder()\ndataset['Label'] = label_encoder.fit_transform(dataset['Label'])\n\n# Split the dataset into training and testing sets\nX = dataset['URL']\ny = dataset['Label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.82, random_state=42)\n\n# RoBERTa Tokenization and Feature Extraction\nmodel_name = \"roberta-base\"\ntokenizer = RobertaTokenizer.from_pretrained(model_name)\nmodel = RobertaForSequenceClassification.from_pretrained(model_name)\n\n# Tokenize and encode the input text\ntrain_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\ntest_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n\n# Create DataLoader for training and testing data\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(list(y_train)))\ntest_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(list(y_test)))\n\n# Parallelize over available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n# Wrap the model with DataParallel\nmodel = torch.nn.DataParallel(model, device_ids = [ 0, 1])\nmodel.to(f'cuda:{model.device_ids[0]}')\n\n# class_weights = torch.tensor([1.0, float(len(y_train[y_train == 0])) / float(len(y_train[y_train == 1]))])\n# class_weights = class_weights.to(device)\n\ntrain_batch_size = 32\ntest_batch_size = 64\n\ntrain_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=train_batch_size)\ntest_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=test_batch_size)\n\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Fine-tuning\nepochs = 6\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=int(0.1 * total_steps),\n    num_training_steps=total_steps,\n)\n\nloss_fn = torch.nn.CrossEntropyLoss()\nmodel.train()\n\n# Initialize variables for loss\nsteps = []\nlosses = []\nfig, ax = plt.subplots()\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch + 1}/{epochs}', leave=False)\n    for step, batch in progress_bar:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs['loss']\n        loss = loss.mean() \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # Append loss values for real-time plot\n        steps.append(len(steps) + 1)\n        losses.append(loss.item())\n\n# Prediction\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    progress_bar = tqdm(test_dataloader, desc='Evaluating', leave=False)\n    for batch in progress_bar:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        predictions.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n\n# Evaluate the model\ny_true = list(y_test)\ny_pred = predictions\naccuracy = accuracy_score(y_true, y_pred)\nclassification_rep = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\nf1 = f1_score(y_true, y_pred, average='weighted')  # Calculate F1 score\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(classification_rep)\n\n# Visualization\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_true, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Class Imbalance Visualization\nsns.countplot(x='Label', data=dataset)\nplt.title('Class Distribution')\nplt.show()\n\n# Precision-Recall Curve\nprecision, recall, _ = precision_recall_curve(y_true, y_pred)\nplt.plot(recall, precision, marker='.')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.show()\n\n# ROC Curve and AUC\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()\n\n#saving the model\nimport pickle\nmodel_save_path = \"roberta_phishing_model.pkl\"\nmodel_state = {\n    'model': model.state_dict(),\n#     'class_weights': class_weights.cpu().numpy(),\n    'test_dataloader':test_dataloader,\n    'train_dataloader': train_dataloader,\n    'device': device,\n    'train_encodings': train_encodings,\n    'test_encodings': test_encodings,\n    'train_dataset': train_dataset,\n    'test_dataset': test_dataset,\n    'tokenizer': tokenizer\n}\n\nwith open(model_save_path, 'wb') as model_file:\n    pickle.dump(model_state, model_file)\n\n# Save training-related data for later visualization\ntraining_data_save_path = \"training_data.pkl\"\ntraining_data = {\n    'steps': steps,\n    'losses': losses\n}\n\nwith open(training_data_save_path, 'wb') as training_data_file:\n    pickle.dump(training_data, training_data_file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**With Class Weights**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, roc_curve, auc, f1_score\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AdamW, get_scheduler\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, auc\nimport seaborn as sns\n\n\n# Load the dataset\ndataset = pd.read_csv(\"/kaggle/input/phishing-site-urls/phishing_site_urls.csv\")\n\n# Data Preprocessing and removeing missing values\ndataset = dataset.dropna()\n\n# Encode labels (good and bad) to numerical values\nlabel_encoder = LabelEncoder()\ndataset['Label'] = label_encoder.fit_transform(dataset['Label'])\n\n# Split the dataset into training and testing sets\nX = dataset['URL']\ny = dataset['Label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.82, random_state=42)\n\n# RoBERTa Tokenization and Feature Extraction\nmodel_name = \"roberta-base\"\ntokenizer = RobertaTokenizer.from_pretrained(model_name)\nmodel = RobertaForSequenceClassification.from_pretrained(model_name)\n\n# Tokenize and encode the input text\ntrain_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\ntest_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n\n# Create DataLoader for training and testing data\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(list(y_train)))\ntest_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(list(y_test)))\n\n# Parallelize over available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n# Wrap the model with DataParallel\nmodel = torch.nn.DataParallel(model, device_ids = [ 0, 1])\nmodel.to(f'cuda:{model.device_ids[0]}')\n\nclass_weights = torch.tensor([1.0, float(len(y_train[y_train == 0])) / float(len(y_train[y_train == 1]))])\nclass_weights = class_weights.to(device)\n\ntrain_batch_size = 32\ntest_batch_size = 64\n\ntrain_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=train_batch_size)\ntest_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=test_batch_size)\n\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Fine-tuning\nepochs = 6\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=int(0.1 * total_steps),\n    num_training_steps=total_steps,\n)\n\nloss_fn = torch.nn.CrossEntropyLoss()\nmodel.train()\n\n# Initialize variables for loss\nsteps = []\nlosses = []\nfig, ax = plt.subplots()\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch + 1}/{epochs}', leave=False)\n    for step, batch in progress_bar:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs['loss']\n        loss = loss.mean() \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # Append loss values for real-time plot\n        steps.append(len(steps) + 1)\n        losses.append(loss.item())\n\n# Prediction\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    progress_bar = tqdm(test_dataloader, desc='Evaluating', leave=False)\n    for batch in progress_bar:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        predictions.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n\n# Evaluate the model\ny_true = list(y_test)\ny_pred = predictions\naccuracy = accuracy_score(y_true, y_pred)\nclassification_rep = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\nf1 = f1_score(y_true, y_pred, average='weighted')  # Calculate F1 score\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(classification_rep)\n\n# Visualization\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_true, y_pred)\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Class Imbalance Visualization\nsns.countplot(x='Label', data=dataset)\nplt.title('Class Distribution')\nplt.show()\n\n# Precision-Recall Curve\nprecision, recall, _ = precision_recall_curve(y_true, y_pred)\nplt.plot(recall, precision, marker='.')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.show()\n\n# ROC Curve and AUC\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()\n\n#saving the model\nimport pickle\nmodel_save_path = \"roberta_phishing_model.pkl\"\nmodel_state = {\n    'model': model.state_dict(),\n    'class_weights': class_weights.cpu().numpy(),\n    'test_dataloader':test_dataloader,\n    'train_dataloader': train_dataloader,\n    'device': device,\n    'train_encodings': train_encodings,\n    'test_encodings': test_encodings,\n    'train_dataset': train_dataset,\n    'test_dataset': test_dataset,\n    'tokenizer': tokenizer\n}\n\nwith open(model_save_path, 'wb') as model_file:\n    pickle.dump(model_state, model_file)\n\n# Save training-related data for later visualization\ntraining_data_save_path = \"training_data.pkl\"\ntraining_data = {\n    'steps': steps,\n    'losses': losses\n}\n\nwith open(training_data_save_path, 'wb') as training_data_file:\n    pickle.dump(training_data, training_data_file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SHAP Values ","metadata":{}},{"cell_type":"code","source":"import shap\nlabels = sorted(model.config.label2id, key=model.config.label2id.get)\n\n\n# This defines an explicit python function that takes a list of strings and outputs scores for each class\ndef f(x):\n    tv = torch.tensor(\n        [\n            tokenizer.encode(v, padding=\"max_length\", max_length=128, truncation=True)\n            for v in x\n        ]\n    ).cuda()\n    attention_mask = (tv != 0).type(torch.int64).cuda()\n    outputs = model(tv, attention_mask=attention_mask)[0].detach().cpu().numpy()\n    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n    val = sp.special.logit(scores)\n    return val","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy as sp\nmethod = \"custom tokenizer\"\n\n# build an explainer by passing a transformers tokenizer\nif method == \"transformers tokenizer\":\n    explainer = shap.Explainer(f, tokenizer, output_names=labels)\n\n# build an explainer by explicitly creating a masker\nelif method == \"default masker\":\n    masker = shap.maskers.Text(r\"\\W\")  # this will create a basic whitespace tokenizer\n    explainer = shap.Explainer(f, masker, output_names=labels)\n\n# build a fully custom tokenizer\nelif method == \"custom tokenizer\":\n    import re\n\n    def custom_tokenizer(s, return_offsets_mapping=True):\n        \"\"\"Custom tokenizers conform to a subset of the transformers API.\"\"\"\n        pos = 0\n        offset_ranges = []\n        input_ids = []\n        for m in re.finditer(r\"\\W\", s):\n            start, end = m.span(0)\n            offset_ranges.append((pos, start))\n            input_ids.append(s[pos:start])\n            pos = end\n        if pos != len(s):\n            offset_ranges.append((pos, len(s)))\n            input_ids.append(s[pos:])\n        out = {}\n        out[\"input_ids\"] = input_ids\n        if return_offsets_mapping:\n            out[\"offset_mapping\"] = offset_ranges\n        return out\n\n    masker = shap.maskers.Text(custom_tokenizer)\n    explainer = shap.Explainer(f, masker, output_names=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = explainer(X_train[:3])\nshap.plots.text(shap_values)","metadata":{},"execution_count":null,"outputs":[]}]}